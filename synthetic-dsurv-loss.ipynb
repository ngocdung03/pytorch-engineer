{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import print_function\n",
    "# import argparse\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable  # change later\n",
    "from torchvision import datasets, transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt \n",
    "from torch.nn.parameter import Parameter # ?\n",
    "\n",
    "from functools import reduce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>label</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>feature12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.440500</td>\n",
       "      <td>-0.035066</td>\n",
       "      <td>-0.025341</td>\n",
       "      <td>-0.029775</td>\n",
       "      <td>-0.55787</td>\n",
       "      <td>-0.15355</td>\n",
       "      <td>0.56819</td>\n",
       "      <td>-0.15432</td>\n",
       "      <td>-0.250230</td>\n",
       "      <td>0.33915</td>\n",
       "      <td>0.70388</td>\n",
       "      <td>0.28174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015579</td>\n",
       "      <td>-0.846080</td>\n",
       "      <td>0.487530</td>\n",
       "      <td>0.651930</td>\n",
       "      <td>0.20099</td>\n",
       "      <td>-0.11238</td>\n",
       "      <td>-1.39630</td>\n",
       "      <td>-0.18874</td>\n",
       "      <td>-0.300010</td>\n",
       "      <td>-0.24032</td>\n",
       "      <td>-0.38533</td>\n",
       "      <td>-1.02450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.446490</td>\n",
       "      <td>1.641000</td>\n",
       "      <td>-1.745000</td>\n",
       "      <td>0.317950</td>\n",
       "      <td>-1.14060</td>\n",
       "      <td>0.36560</td>\n",
       "      <td>0.28110</td>\n",
       "      <td>-0.58253</td>\n",
       "      <td>-1.690700</td>\n",
       "      <td>1.20220</td>\n",
       "      <td>-0.51920</td>\n",
       "      <td>1.78400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.629460</td>\n",
       "      <td>-0.615750</td>\n",
       "      <td>-0.323450</td>\n",
       "      <td>-0.900200</td>\n",
       "      <td>0.45360</td>\n",
       "      <td>-0.61992</td>\n",
       "      <td>2.16240</td>\n",
       "      <td>0.19875</td>\n",
       "      <td>-1.119600</td>\n",
       "      <td>-2.73210</td>\n",
       "      <td>-0.25673</td>\n",
       "      <td>-0.81836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.249800</td>\n",
       "      <td>-0.185610</td>\n",
       "      <td>-0.183780</td>\n",
       "      <td>-0.981080</td>\n",
       "      <td>-0.01499</td>\n",
       "      <td>-0.14437</td>\n",
       "      <td>-1.25290</td>\n",
       "      <td>-0.58432</td>\n",
       "      <td>-0.090523</td>\n",
       "      <td>0.93692</td>\n",
       "      <td>1.07490</td>\n",
       "      <td>0.79117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time  label  feature1  feature2  feature3  feature4  feature5  feature6  \\\n",
       "0     0      0 -0.440500 -0.035066 -0.025341 -0.029775  -0.55787  -0.15355   \n",
       "1     1      0  0.015579 -0.846080  0.487530  0.651930   0.20099  -0.11238   \n",
       "2    34      2  0.446490  1.641000 -1.745000  0.317950  -1.14060   0.36560   \n",
       "3     9      0  0.629460 -0.615750 -0.323450 -0.900200   0.45360  -0.61992   \n",
       "4     2      0  1.249800 -0.185610 -0.183780 -0.981080  -0.01499  -0.14437   \n",
       "\n",
       "   feature7  feature8  feature9  feature10  feature11  feature12  \n",
       "0   0.56819  -0.15432 -0.250230    0.33915    0.70388    0.28174  \n",
       "1  -1.39630  -0.18874 -0.300010   -0.24032   -0.38533   -1.02450  \n",
       "2   0.28110  -0.58253 -1.690700    1.20220   -0.51920    1.78400  \n",
       "3   2.16240   0.19875 -1.119600   -2.73210   -0.25673   -0.81836  \n",
       "4  -1.25290  -0.58432 -0.090523    0.93692    1.07490    0.79117  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/chl8856/DeepHit/master/sample%20data/SYNTHETIC/synthetic_comprisk.csv'\n",
    "dataset = pd.read_csv(url)\n",
    "dataset.drop(['true_time', 'true_label'], axis=1, inplace=True)\n",
    "dataset.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data\n",
    "# df = df.sample(frac=1).reset_index(drop=True)\n",
    "# df\n",
    "\n",
    "# df.futime.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 14)\n",
      "time           int64\n",
      "label          int64\n",
      "feature1     float64\n",
      "feature2     float64\n",
      "feature3     float64\n",
      "feature4     float64\n",
      "feature5     float64\n",
      "feature6     float64\n",
      "feature7     float64\n",
      "feature8     float64\n",
      "feature9     float64\n",
      "feature10    float64\n",
      "feature11    float64\n",
      "feature12    float64\n",
      "dtype: object\n",
      "time         0\n",
      "label        0\n",
      "feature1     0\n",
      "feature2     0\n",
      "feature3     0\n",
      "feature4     0\n",
      "feature5     0\n",
      "feature6     0\n",
      "feature7     0\n",
      "feature8     0\n",
      "feature9     0\n",
      "feature10    0\n",
      "feature11    0\n",
      "feature12    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)\n",
    "print(dataset.dtypes)\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values processing\n",
    "# print(df['creatinine'].mean())\n",
    "# df['creatinine'] = df['creatinine'].fillna(df['creatinine'].mean())\n",
    "# df = df.drop(columns=['chapter'])\n",
    "# print(df.isnull().sum())\n",
    "\n",
    "# pd.get_dummies(df.sex)\n",
    "# df.sex.replace(['F', 'M'], [0, 1], inplace=True)\n",
    "# df.sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        0\n",
      "2        1\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "29995    1\n",
      "29996    1\n",
      "29997    0\n",
      "29998    0\n",
      "29999    0\n",
      "Name: label, Length: 30000, dtype: int64\n",
      "0        0\n",
      "1        0\n",
      "2        1\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "29995    1\n",
      "29996    1\n",
      "29997    0\n",
      "29998    0\n",
      "29999    0\n",
      "Name: label, Length: 30000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Change values of outcome\n",
    "print(dataset['label'])\n",
    "dataset['label'].replace({2:1}, inplace=True)\n",
    "print(dataset['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train - test - validation split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_x = lambda df: (df\n",
    "                    .drop(columns=['time', 'label'])\n",
    "                    .values.astype('float32'))\n",
    "\n",
    "df_test = dataset.sample(frac=0.2)\n",
    "df_train = dataset.drop(df_test.index)\n",
    "# df_val = df_train.sample(frac=0.2)\n",
    "# df_train = df_train.drop(df_val.index)\n",
    "\n",
    "X_train = get_x(df_train)\n",
    "X_test = get_x(df_test)\n",
    "\n",
    "Y_train = df_train[['label', 'time']].to_numpy()\n",
    "Y_test = df_test[['label', 'time']].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_in, H, D_out = X_train.shape[1], 128, 32    # D_out 32 ?\n",
    "batch_size = 32\n",
    "num_time_units = 24 # 24 month?\n",
    "time_bin = 30   # 30?\n",
    "n_epochs = 1\n",
    "learning_rate = 1e-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class survdl(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out, num_time_units):\n",
    "        super(survdl, self).__init__()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.fc_layer = nn.Sequential(nn.Linear(D_in, H), nn.ReLU(), nn.Dropout(0.5), nn.Linear(H, D_out))\n",
    "        self.fc_layer2 = nn.Linear(1, num_time_units)\n",
    "        self.beta = Parameter(torch.Tensor(D_out, 1))\n",
    "        self.beta.data.uniform_(-0.001, 0.001)  # initialization?\n",
    "        \n",
    "    def score_1(self, x):\n",
    "        return torch.exp(x.mm(self.beta))  # hazard function - s1\n",
    "    \n",
    "    def score_2(self, score1):\n",
    "        return self.sigmoid(self.fc_layer2(score1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        new_x = self.fc_layer(x)\n",
    "        score1 = self.score_1(new_x)\n",
    "        score2 = self.score_2(score1)\n",
    "        return score1, score2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function for C-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_set(lifetime):\n",
    "    a = lifetime.data.cpu().numpy()   # lifetime.data.cpu().numpy()\n",
    "    t, idx = np.unique(a, return_inverse=True)\n",
    "    sort_idx = np.argsort(a)\n",
    "    a_sorted = a[sort_idx]\n",
    "    unq_first = np.concatenate(([True], a_sorted[1:] != a_sorted[:-1]))\n",
    "    unq_count = np.diff(np.nonzero(unq_first)[0])\n",
    "    unq_idx = np.split(sort_idx, np.cumsum(unq_count))\n",
    "    return t, unq_idx\n",
    "    \n",
    "def log_parlik(lifetime, censor, score1):  \n",
    "    t, H = unique_set(lifetime)\n",
    "    keep_index = np.nonzero(censor.data.cpu().numpy())[0]  #censor = 1  #.data.cpu()\n",
    "    H = [list(set(h)&set(keep_index)) for h in H]\n",
    "    n = [len(h) for h in H]\n",
    "    \n",
    "    score1 = score1.detach().data.cpu().numpy()   # .data.cpu()   #?\n",
    "    total = 0\n",
    "    for j in range(len(t)):\n",
    "        total_1 = np.sum(np.log(score1)[H[j]])\n",
    "        m = n[j]\n",
    "        total_2 = 0\n",
    "        for i in range(m):\n",
    "            subtotal = np.sum(score1[sum(H[j:],[])]) - (i*1.0/m)*(np.sum(score1[H[j]]))\n",
    "            subtotal = np.log(subtotal)\n",
    "            total_2 = total_2 + subtotal\n",
    "        total = total + total_1 - total_2\n",
    "        total = np.array([total])\n",
    "    return torch.Tensor(total).type(torch.FloatTensor).to(device).view(-1,1)\n",
    "        \n",
    "\n",
    "def acc_pairs(censor, lifetime):\n",
    "    noncensor_index = np.nonzero(censor.data.cpu().numpy())[0]\n",
    "    lifetime = lifetime.data.cpu().numpy()\n",
    "    acc_pair = []\n",
    "    for i in noncensor_index:\n",
    "        all_j =  np.array(range(len(lifetime)))[lifetime > lifetime[i]]\n",
    "        acc_pair.append([(i,j) for j in all_j])\n",
    "    \n",
    "    acc_pair = reduce(lambda x,y: x + y, acc_pair)\n",
    "    return acc_pair\n",
    "\n",
    "\n",
    "def rank_loss(lifetime, censor, score2, t, time_bin): \n",
    "    # score2 (n(samples)*24) at time unit t = 1,2,...,24\n",
    "    acc_pair = acc_pairs(censor, lifetime)\n",
    "    lifetime = lifetime.data.cpu().numpy()\n",
    "    total = 0\n",
    "    for i,j in acc_pair:\n",
    "        yi = (lifetime[i] >= (t-1) * time_bin) * 1\n",
    "        yj = (lifetime[j] >= (t-1) * time_bin) * 1\n",
    "        a = torch.ones(1).type(torch.FloatTensor).to(device)\n",
    "        L2dist = torch.dist(score2[j, t-1] - score2[i, t-1], a, 2)\n",
    "        total = total + L2dist* yi * (1-yj)\n",
    "    return total\n",
    "\n",
    "\n",
    "def C_index(censor, lifetime, score1):\n",
    "    score1 = score1.detach().data.cpu().numpy()  #.data.cpu()  #?\n",
    "    acc_pair = acc_pairs(censor, lifetime)\n",
    "    prob = sum([score1[i] >= score1[j] for (i, j) in acc_pair])[0]*1.0/len(acc_pair)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = survdl(D_in, H, D_out, num_time_units).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training and evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.2869e+00 -1.2126e+00 -7.8916e-01 ...  7.5659e-01  6.2747e-01\n",
      "   4.1510e-01]\n",
      " [ 2.6148e-01 -1.7578e+00  1.2720e-03 ... -1.1731e+00  6.3678e-01\n",
      "  -1.1846e-01]\n",
      " [ 4.1238e-01 -7.1887e-01 -4.9787e-01 ...  1.5872e+00  2.3396e-01\n",
      "  -1.9114e-01]\n",
      " ...\n",
      " [ 2.2060e+00 -3.7553e-02  7.7608e-01 ... -2.0386e+00  8.5972e-01\n",
      "  -2.4876e-01]\n",
      " [-1.3101e+00  1.0438e+00 -5.0588e-01 ... -1.0752e+00 -5.9242e-01\n",
      "  -9.6196e-01]\n",
      " [-1.3666e-01 -7.5170e-01 -1.5467e+00 ... -3.0804e-01 -1.8159e-01\n",
      "  -1.1973e+00]] [[-0.4405   -0.035066 -0.025341 ...  0.33915   0.70388   0.28174 ]\n",
      " [ 0.015579 -0.84608   0.48753  ... -0.24032  -0.38533  -1.0245  ]\n",
      " [ 0.44649   1.641    -1.745    ...  1.2022   -0.5192    1.784   ]\n",
      " ...\n",
      " [-0.69875  -0.79495   0.47968  ... -0.88256  -0.13188   0.71109 ]\n",
      " [ 0.16694  -0.47959  -1.2024   ...  0.32197   0.35811  -0.22775 ]\n",
      " [ 0.23814   0.99571   0.61698  ...  1.3149    0.74628   0.071198]]\n",
      "[[ 0 26]\n",
      " [ 0  9]\n",
      " [ 1 17]\n",
      " ...\n",
      " [ 1 98]\n",
      " [ 0 34]\n",
      " [ 0  1]] [[ 0  0]\n",
      " [ 0  1]\n",
      " [ 1 34]\n",
      " ...\n",
      " [ 0  2]\n",
      " [ 0 68]\n",
      " [ 0  4]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test, X_train)\n",
    "print(Y_test, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1 training loss: -0.0013\n",
      "====> Epoch: 1 testing loss: -0.9856\n"
     ]
    }
   ],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0    \n",
    "    # idx = np.random.permutation(X_train.shape[0])     \n",
    "    j = 0\n",
    "    while j < X_train.shape[0]:\n",
    "        if j < X_train.shape[0] - batch_size:\n",
    "            data = Variable(torch.from_numpy(X_train[j:(j + batch_size)])).type(torch.FloatTensor).to(device)\n",
    "            lifetime = Variable(torch.from_numpy(Y_train[j:(j + batch_size),1])).type(torch.FloatTensor).to(device)\n",
    "            censor = Variable(torch.from_numpy(Y_train[j:(j + batch_size),0])).type(torch.FloatTensor).to(device)\n",
    "        else:\n",
    "            data = Variable(torch.from_numpy(X_train[j:])).type(torch.FloatTensor).to(device)\n",
    "            lifetime = Variable(torch.from_numpy(Y_train[j:,1])).type(torch.FloatTensor).to(device)\n",
    "            censor = Variable(torch.from_numpy(Y_train[j:,0])).type(torch.FloatTensor).to(device)\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        score1, score2 = model(data)\n",
    "        loss1 = log_parlik(lifetime, censor, score1)\n",
    "        loss2 = []\n",
    "        for t in range(num_time_units):\n",
    "            loss2.append(rank_loss(lifetime, censor, score2, t+1, time_bin))\n",
    "        loss2 = sum(loss2)\n",
    "        loss = 1.0 * loss1 + 0.5 * loss2\n",
    "        loss.backward()      \n",
    "        train_loss = loss.data[0]\n",
    "        optimizer.step()\n",
    "        j += batch_size\n",
    "    return train_loss*1.0 / X_train.shape[0]\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    j = 0\n",
    "    while j < X_test.shape[0]:\n",
    "        if j < X_test.shape[0] - batch_size:\n",
    "            data = Variable(torch.from_numpy(X_test[j:(j + batch_size)])).type(torch.FloatTensor).to(device)\n",
    "            lifetime = Variable(torch.from_numpy(Y_test[j:(j + batch_size),1])).type(torch.FloatTensor).to(device)\n",
    "            censor = Variable(torch.from_numpy(Y_test[j:(j + batch_size),0])).type(torch.FloatTensor).to(device)\n",
    "        else:\n",
    "            data = Variable(torch.from_numpy(X_test[j:])).type(torch.FloatTensor).to(device)\n",
    "            lifetime = Variable(torch.from_numpy(Y_test[j:,1])).type(torch.FloatTensor).to(device)\n",
    "            censor = Variable(torch.from_numpy(Y_test[j:,0])).type(torch.FloatTensor).to(device)\n",
    "        y_pred = model(data)\n",
    "        score1, score2 = model(data)\n",
    "        loss1 = log_parlik(lifetime, censor, score1)\n",
    "        loss2 = []\n",
    "        for t in range(num_time_units):\n",
    "            loss2.append(rank_loss(lifetime, censor, score2, t+1, time_bin))\n",
    "        loss2 = sum(loss2)\n",
    "        loss = 1.0 * loss1 + 0.5 * loss2\n",
    "        test_loss += loss.data[0]\n",
    "        j += batch_size\n",
    "    return test_loss*1.0 / X_test.shape[0]\n",
    "    \n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train_loss = train(epoch)\n",
    "    test_loss = test(epoch)\n",
    "    print('====> Epoch: %d training loss: %.4f'%(epoch, train_loss))\n",
    "    print('====> Epoch: %d testing loss: %.4f'%(epoch, test_loss))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concordance - training\n",
    "data_train = Variable(torch.from_numpy(X_train)).type(torch.FloatTensor).to(device)\n",
    "lifetime_train = Variable(torch.from_numpy(Y_train[:,0])).type(torch.FloatTensor).to(device)\n",
    "censor_train = Variable(torch.from_numpy(Y_train[:,1])).type(torch.FloatTensor).to(device)\n",
    "\n",
    "score1_train, score2_train = model(data_train)\n",
    "C_index_train = C_index(censor_train, lifetime_train, score1_train)\n",
    "print('Concordance index for training data: {:.4f}'.format(C_index_train))\n",
    "\n",
    "\n",
    "# concordance - test\n",
    "data_test = Variable(torch.from_numpy(X_test)).type(torch.FloatTensor).to(device)\n",
    "lifetime_test = Variable(torch.from_numpy(Y_test[:,0])).type(torch.FloatTensor).to(device)\n",
    "censor_test = Variable(torch.from_numpy(Y_test[:,1])).type(torch.FloatTensor).to(device)\n",
    "\n",
    "score1_test, score2_test = model(data_test)\n",
    "C_index_test = C_index(censor_test, lifetime_test, score1_test)\n",
    "print('Concordance index for test data: {:.4f}'.format(C_index_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9e2b3cd2829f09aa4cbce26e91031c8f0c76a211d73914c4bed7f6ce2202e3c6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
